{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n",
      "[1]\n",
      "[1 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from os.path import basename, join\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers.convolutional import Conv2D\n",
    "#from keras.layers.pooling import MaxPooling2D\n",
    "#from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, History\n",
    "from keras.models import load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from os.path import basename, join\n",
    "from glob import glob\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.utils import print_summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def read_csv(filename):\n",
    "    res = {}\n",
    "    with open(filename) as fhandle:\n",
    "        next(fhandle)\n",
    "        for line in fhandle:\n",
    "            parts = line.rstrip('\\n').split(',')\n",
    "            coords = array([float(x) for x in parts[1:]], dtype='float64')\n",
    "            res[parts[0]] = coords\n",
    "    return res\n",
    "\n",
    "def train_classifier(train_gt, train_img_dir, fast_train = True):    \n",
    "    new_height = 200\n",
    "    new_width = 200\n",
    "    num_classes = 50\n",
    "    \n",
    "    jpeg_list = sorted(glob(join(train_img_dir, '*jpg')))\n",
    "    num_samples = len(jpeg_list)\n",
    "    \n",
    "    X = np.zeros([num_samples, new_height, new_width, 3])\n",
    "    y = np.zeros([num_samples, num_classes])\n",
    "    \n",
    "    count = 0\n",
    "    for path in jpeg_list:\n",
    "        image = imread(path)\n",
    "        \n",
    "        # resize the image\n",
    "        scale_width = image.shape[1] / new_width\n",
    "        scale_height = image.shape[0] / new_height\n",
    "        image_resized = resize(image, (new_height, new_width))\n",
    "        \n",
    "        # handle grayscale images\n",
    "        if len(image_resized.shape) == 2:\n",
    "            tmp_image = np.zeros([new_height, new_width, 3])\n",
    "            tmp_image[:, :, 0] = image_resized\n",
    "            tmp_image[:, :, 1] = image_resized\n",
    "            tmp_image[:, :, 2] = image_resized\n",
    "            image_resized = tmp_image\n",
    "        \n",
    "        X[count] = image_resized\n",
    "        class_ind = int(train_gt[basename(path)])\n",
    "        y[count, class_ind] = 1\n",
    "        \n",
    "        count = count + 1\n",
    "    \n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    X_test = None\n",
    "    y_test = None\n",
    "    \n",
    "    if fast_train is not True:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                            random_state = 2017, shuffle = True,\n",
    "                                                            stratify = y)\n",
    "    \n",
    "    base_model = ResNet50(include_top = False, weights='imagenet', input_shape = [new_height, new_width, 3])\n",
    "    #print_summary(base_model)\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    #checkpointer = ModelCheckpoint(filepath = 'birds_model.hdf5', verbose = 1, save_best_only = True)\n",
    "\n",
    "    epochs = 4000\n",
    "    batch_size = 50\n",
    "\n",
    "    if fast_train is True:\n",
    "        epochs = 1\n",
    "    \n",
    "    # train the model on the new data\n",
    "    #print_summary(model)\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              validation_data = (X_test, y_test),\n",
    "              epochs=epochs,\n",
    "              callbacks = [checkpointer]\n",
    "             )\n",
    "\n",
    "    #model.save(\"birds_model.hdf5\")\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def classify(model, test_img_dir):\n",
    "    new_height = 200\n",
    "    new_width = 200\n",
    "    num_classes = 50\n",
    "    \n",
    "    jpeg_list = sorted(glob(join(test_img_dir, '*jpg')))\n",
    "    num_samples = len(jpeg_list)\n",
    "    \n",
    "    X = np.zeros([num_samples, new_height, new_width, 3])\n",
    "    y = np.zeros([num_samples, num_classes])\n",
    "    \n",
    "    count = 0\n",
    "    test_gt = {}\n",
    "    test_filenames = []\n",
    "    for path in jpeg_list:\n",
    "        image = imread(path)\n",
    "        test_gt[basename(path)] = 0\n",
    "        \n",
    "        # resize the image\n",
    "        scale_width = image.shape[1] / new_width\n",
    "        scale_height = image.shape[0] / new_height\n",
    "        image_resized = resize(image, (new_height, new_width))\n",
    "        \n",
    "        # handle grayscale images\n",
    "        if len(image_resized.shape) == 2:\n",
    "            tmp_image = np.zeros([new_height, new_width, 3])\n",
    "            tmp_image[:, :, 0] = image_resized\n",
    "            tmp_image[:, :, 1] = image_resized\n",
    "            tmp_image[:, :, 2] = image_resized\n",
    "            image_resized = tmp_image\n",
    "        \n",
    "        X[count] = image_resized\n",
    "        test_filenames.append(basename(path))\n",
    "        count = count + 1\n",
    "    \n",
    "    yy = model.predict(X)\n",
    "    y = np.where(yy == 1)[1]\n",
    "    \n",
    "    for picture_ind in range(len(test_filenames)):\n",
    "        test_filename = test_filenames[picture_ind]\n",
    "        test_gt[test_filename] = y[picture_ind]\n",
    "\n",
    "    return test_gt\n",
    "\n",
    "\n",
    "# call to train a model\n",
    "#train_dir = 'data/00_input/train'\n",
    "#train_img_dir = 'data/00_input/train/images'\n",
    "#train_gt = read_csv(join(train_dir, 'gt.csv'))\n",
    "#train_classifier(train_gt, train_img_dir, False)\n",
    "\n",
    "# call to test trained model\n",
    "#test_img_dir = 'data/00_input/test/images'\n",
    "#model = load_model('facepoints_model.hdf5')\n",
    "#detected_points = detect(model, test_img_dir)\n",
    "           \n",
    "#print(detected_points)\n",
    "\n",
    "y = np.array([[0, 1, 0],\n",
    "              [1, 0, 0],\n",
    "              [1, 0, 0],\n",
    "              [0, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 0]])\n",
    "\n",
    "print(y.shape)\n",
    "inds = np.where(y == 1)[1]\n",
    "\n",
    "a = np.array([0, 1, 0, 0])\n",
    "\n",
    "print(np.where(a == 1)[0][0])\n",
    "\n",
    "print(inds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
